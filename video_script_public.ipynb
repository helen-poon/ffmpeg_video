{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58493dd5-2d67-4b0d-850d-0f320062e97c",
   "metadata": {},
   "source": [
    "<h3 align = center>How to make a simple video using FFMPEG</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a576c46-0d2e-481f-834e-2c4014d6fc38",
   "metadata": {},
   "source": [
    "Introduciton: Recently, I helped someone to make youtube videos. Originally I used a interface software but the free version has a lot of limitations. Plus, using a command-line software can be faster for certain functions (but for others interface version is better). I use AI to write the majority of the code here. At first, I thought it was easy but it turned out to be a lot more complicated than I thought. I will explain below. Though complicated, I learnt some techinical stuff about videos. <br>\n",
    "And, recently, I started learning data science and learnt to use Jupyter Notebook. I find Jupyter Notebook a lot easier when I need to run a script of many different functions. <br>\n",
    "In this tutorial, you will learn some basics of making a video using FFMPEG, including: <br>\n",
    "- how to overlay video, music and images on the main video\n",
    "- how to combine different videos\n",
    "- how to trim a video\n",
    "- how to use subtitle in ass format and burn it in a video\n",
    "- how to add a mosiac\n",
    "- how to extract audio and convert to text\n",
    "- how to translate the subtitle to different languages\n",
    "- how to zoom in an image\n",
    "- how to concatenate videos\n",
    "- how to insert a black still(or other colors) with text when introducing a topic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b2ba06-62de-40a0-a643-7e95fb48deec",
   "metadata": {},
   "source": [
    "<h3 align = center>Things you need to download</h3>\n",
    "The most important is <i><b>ffmpeg</b></i>. Use home brew to download it (I am using Mac). <br>\n",
    "Here are the python packages I use:  <br>\n",
    "<i>subprocess, os, sys, shlex, pathlib, re,datetime, math, json, PIL, fractions, matplotli, tempfile, shutil, cv2, numpy, whisper, demucs, opencc</i> <br><br>\n",
    "When you install <i>whisper</i>(for converting audio to subtitles) and <i>demucs</i>(for separating different audio channels), you probably need to set up another python environment. As of now, the latest python version is not compatible. When you run these two, you need to switch the environment first.<br>\n",
    "The code we are using here is in <b><i>video_commands.py</i></b>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ad4852-3370-4474-8cd6-021a0c95890c",
   "metadata": {},
   "source": [
    "<h3 align = center> Let's begin! </h3>\n",
    "The media files used in this file are in the folder <i>media_files</i>. The main video is a documentary in 1944 called <i>Marines at Tarawa - Return to Guam</i>. Originall it is 40 minutes but I already trimmed it to 5 minutes. This is the main video of this tutorial called <i><b>marines_5min.mov</i></b>. If you want to trim it yourself, you can download it here: <br>\n",
    "<a href =\"https://archive.org/details/publicmovies212/Marines_at_Tarawa_Return_to_Guam.webm\">https://archive.org/details/publicmovies212/Marines_at_Tarawa_Return_to_Guam.webm</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475c2024-5b9d-4a3d-a09b-cf2e4bc99bf7",
   "metadata": {},
   "source": [
    "<h3 align = center>Trimming a video </h3>\n",
    "Say, we want to extract <i>11:00 to 16:00</i> from the video Marines_at_Tarawa_Return_to_Guam.mp4(the original 40-min video) and rename the output to <i>media_files/marines_5min.mov</i>, here is the ffmpeg command:<br><br>\n",
    "<i>ffmpeg -y -ss 11:00 -to 16:00 -i Marines_at_Tarawa_Return_to_Guam.mp4 -c:v libx264 -preset veryfast -crf 18 -c:a copy  media_files/marines_5min.mov</i> <br><br>\n",
    "Below is the python version. Pay attention to these parameters in the above ffmpeg command:<br><br>\n",
    "<b><i>-c:v libx264 -preset veryfast -crf 18</i></b>  <br><br>\n",
    "HEVC 264(libx264) is a very common compression format and compatible with most video players. An efficient compression format can give you a similar video quality and smaller file size.(This is something new I learn. I used to think the larger the size, the better the quality!) <br><br>\n",
    "And the actual quality depends on <b><i>crf</i></b> and <b><i>preset</i></b>. <b><i>crf</i></b> ranges from 0 - 50. The smaller the value, the better the quality. <b><i>preset</i></b> has values of \"veryslow\",\"slow\",\"medium\",\"fast\",\"veryfast\" and \"ultrafast\". These two together determine the compression time and file size. If you choose a small value of <b><i>crf</i></b> and \"veryslow\" for <b><i>preset</i></b>, you end up having a video a lot larger than the original.<br><br>\n",
    "\n",
    "Usually, <b><i> -crf 18 -preset fast</b></i> is good enough. You can do an experiment by re-encoding a high resolution video with different <i>crf</i> and <i>preset</i> parameters and see how the quality changes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fabe0b9-ac33-49dd-bc48-31c3d4e7b302",
   "metadata": {},
   "outputs": [],
   "source": [
    "from video_commands import * \n",
    "main_video = \"Marines_at_Tarawa_Return_to_Guam.mp4\"\n",
    "start_time = \"11:00\" #you can enter as 1)an interger which is second, 2)mm:ss, or 3)hh:mm:ss\n",
    "end_time = \"16:00\" \n",
    "output_file = \"media_files/marines_5min.mov\"\n",
    "trim_video(main_video, start_time, end_time, output_file,crf=18, preset = \"fast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f841262e-07cc-43d0-a0b4-dd032bbf3e67",
   "metadata": {},
   "source": [
    "<h3 align = center>Codec of a video</h3>\n",
    "Now we have produced the main video, let's take a look at the codec(technical details). It has got video and audio parts:<br>\n",
    "ffmpeg code for video: <br>\n",
    "<i>ffprobe -v error -select_streams v:0 -show_entries stream=codec_name,width,height,r_frame_rate,pix_fmt -of csv=p=0 media_files/marines_5min.mov</i>\n",
    "ffmpeg code for audio: <br>\n",
    "<i>ffprobe -v error -select_streams a:0 -show_entries stream=codec_name,sample_rate,channels -of csv=p=0 media_files/marines_5min.mov</i>\n",
    "<br><br>\n",
    "Now let's run the code below:<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3982c896-3204-4eae-8fe6-09664e0a808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from video_commands import * \n",
    "file_list = [\"media_files/marines_5min.mov\"]\n",
    "print_media_info(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9c2b5e-eddf-4505-a336-3859d384d3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from video_commands import * \n",
    "file_list = [\"media_files/marines_5min.mov\"]\n",
    "print_media_info(file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae6388b-89ac-4393-9282-5b4f51241dd4",
   "metadata": {},
   "source": [
    "<h3 align = center>Splitting a video into sections and combining with black stills</h3>\n",
    "For my video, I need to insert a few black stills to separate the video in different sections. The black still looks like this:\n",
    "<p align=\"center\">\n",
    "    <img src=\"https://helen-poon.github.io/ffmpeg_video/black_screen.png\" \n",
    "         alt=\"Black screen separator\" \n",
    "         style=\"max-width: 100%; height: auto;\">\n",
    "</p>\n",
    "\n",
    "\n",
    "Say, the first black still appears at 1:30, the second one 2:30 and the third one 4:00. Then we have to split the video into different sections: <br>\n",
    "1) 0:00 - 1:30 <br>\n",
    "2) 1:30 - 2:30 <br>\n",
    "3) 2:30 - 4:00 <br>\n",
    "4) 4:00 - the end <br>\n",
    "First, let's split the main video into 4 sections, namely <i>video1.mov</i>, <i>video2.mov</i>, <i>video3.mov</i> and <i>video4.mov</i><br><br>\n",
    "<i>ffmpeg -y -ss 0.000 -i media_files/marines_5min.mov -t 90.000 -c:v libx264 -preset fast -c:a pcm_s16le -ar 48000 -ac 2 -movflags +faststart video1.mov</i><br>\n",
    "<i> ffmpeg -y -ss 90.000 -i media_files/marines_5min.mov -t 60.000 -c:v libx264 -preset fast -c:a pcm_s16le -ar 48000 -ac 2 -movflags +faststart video2.mov</i><br>\n",
    "<i>ffmpeg -y -ss 150.000 -i media_files/marines_5min.mov -t 90.000 -c:v libx264 -preset fast -c:a pcm_s16le -ar 48000 -ac 2 -movflags +faststart video3.mov </i><br>\n",
    "<i>ffmpeg -y -ss 240.000 -i media_files/marines_5min.mov -t 60.009 -c:v libx264 -preset fast -c:a pcm_s16le -ar 48000 -ac 2 -movflags +faststart video4.mov\n",
    " </i><br><br>\n",
    "\n",
    " Below is the python code. Let's run it.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12542ec0-a165-4ba0-ac09-1e21204f62fd",
   "metadata": {},
   "source": [
    "Here is the output on the screen when you run the python code above:<br><br>\n",
    "\n",
    "---- media_files/marines_5min.mov ---- <br>\n",
    "video info:  ffprobe -v error -select_streams v:0 -show_entries stream=codec_name,width,height,r_frame_rate,pix_fmt -of csv=p=0 <br> media_files/marines_5min.mov<br>\n",
    "Video: h264,556,412,yuv420p,25/1 <br>\n",
    "audio info:  ffprobe -v error -select_streams a:0 -show_entries stream=codec_name,sample_rate,channels -of csv=p=0 <br>media_files/marines_5min.mov<br>\n",
    "Audio: aac,44100,2<br>\n",
    "video start and end time:0.000000,300.000000<br>\n",
    "audio start and end time:0.000000,300.009002<br>\n",
    "\n",
    "For the video part: <br>\n",
    "<i>h264</i> is the compression format I just talked about<br>\n",
    "<i>556,412 </i>are the width and height of the video respectively<br>\n",
    "<i>yuv420p</i> is the Chroma Subsampling Scheme. I don't know the importance of this.<br>\n",
    "<i>25/1</i> is the frame rate<br>\n",
    "\n",
    "For the audio part: <br>\n",
    "<i>aac</i> is the most commom audio codec\n",
    "<i>44100</i>(44.1kHz) us  the standard sample rate for audio CDs\n",
    "<i>2</i> The number of audio channels\n",
    "\n",
    "When concatenating videos of different format, they have to be re-encoded first or concatenation would fail. We will get back to this later. <br>\n",
    "The most important thing to note here is the final lines: <br>\n",
    "<i>video start and end time:0.000000,300.000000<br>\n",
    "audio start and end time:0.000000,300.009002</i><br>\n",
    "\n",
    "You see the video and audio don't have the same duration. This would cause asynchronization when concatenating different videos(even though the difference is < 0.1s, the asynchronization is noticeable). You see the video and audio don't match. I struggled a lot to understand this. I used to think it was the problem of the ffmpeg command but indeed it is not. You have to trim either the video or the audio so that the duration match. We will do this later.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6349cf43-64b1-4bc5-8197-843f70700c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_video = \"media_files/marines_5min.mov\"\n",
    "the_end = get_video_length(main_video) #we retrive the exact end time in hh:mm:ss by calling this function\n",
    "sections = [\"0:00 - 1:30\",\"1:30 - 2:30\",\"2:30 - 4:00\",f\"4:00-{the_end}\"]\n",
    "#Below are the output files. The length of this list has to match the length of sections\n",
    "output_files = [\"video1.mov\",\"video2.mov\",\"video3.mov\",\"video4.mov\"] \n",
    "split_video(main_video, sections, output_files, audio_codec=\"wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3b466b-6ad5-483c-9212-d92aa7d9b6ca",
   "metadata": {},
   "source": [
    "<h3 align = center>Creating a black still</h3>\n",
    "Now we are going to create some black stills to be inserted into the video. The main video has 4 different sections, so we insert 3 black stills. Say, the text are \"Section 1\", \"Section 2\", and \"Section 3\", each last for 5 seconds. The output names are  \"black1.mov\",\"black2.mov\"and \"black3.mov\". We first create a blank black still with the same dimensions(556x412) as the main video:<br><br>\n",
    "\n",
    "<i>ffmpeg -y -f lavfi -i color=c=black:s=556x412:r=25.0:d=5 -f lavfi -i anullsrc=r=44100:cl=stereo -shortest -c:v libx264 -pix_fmt yuv420p -c:a pcm_s16le temp_black.mp4</i><br>\n",
    "\n",
    "Then python creates an ass file with the text called <i>temp_sub.ass</i>. Finally <i>temp_sub.ass</i> is burnt in to <i>temp_black.mp4</i> and the final output is what we want.\n",
    "\n",
    "<i>ffmpeg -y -i temp_black.mp4 -vf ass=temp_sub.ass -c:v libx264 -pix_fmt yuv420p -c:a copy black1.mov</i>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80869c5e-4324-4ba4-b46a-604c99fba1d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from video_commands import * \n",
    "main_video = \"media_files/marines_5min.mov\"\n",
    "text = [\"Section 1\",\"Section 2\",\"Section 3\"]\n",
    "output_files = [\"black1.mov\",\"black2.mov\",\"black3.mov\"]\n",
    "duration = 5 # in seconds\n",
    "for txt,output_names in zip(text,output_files):\n",
    "    output_file = create_black_still(main_video,txt,duration,output_names,font_name=\"Arial\",font_size=72,\n",
    "    font_color=\"&H00FFFFFF\" #Solid White\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d8de5b-c47e-475d-97ef-2041e37d5d10",
   "metadata": {},
   "source": [
    "The black stills are produced with the same codec as the main video, we can check them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8943b9-1421-4114-88d0-078b0cb5e8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = [\"media_files/marines_5min.mov\",\"video1.mov\",\"video2.mov\",\"video3.mov\",\"video5.mov\",\n",
    "            \"black1.mov\",\"black2.mov\",\"black3.mov\"]\n",
    "print_media_info(file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8a45a7-d7d2-428a-8b31-ef92195a2bd2",
   "metadata": {},
   "source": [
    "You see the video codecs are the same, but the audio codec is <i>pcm_s16l</i> for the segmented videos and black stills. This format is loseless and preserves the quality. But for the final audio format, we will convert to aac. Also note that for the black stills, the audio duration and video duration do not match. We are going to deal with this with the following function. It first extracts the codec from the main video, then convert other videos with the same codec, finally trim the video or audio duration so that they match. If a video has no audio stream, this function would add a silent one. <br>\n",
    "<b>Note that this step is actually unnecessary because it is incorporated in the next function <i>combine_video()</i></b>. I am just showing what reencoding does here. This process may take > 10 mins. To speed things up, change the <i>crf</i> and <i>preset</i> values.<br>\n",
    "\n",
    "Here is the break down of <i>reencode_to_match()</i>:<br>\n",
    "1)Get main video's codec: <br>\n",
    "<i>ffprobe -v error -select_streams v:0 -show_entries stream=width,height,r_frame_rate,duration -of json media_files/marines_5min.mov\n",
    "</i><br>\n",
    "\n",
    "The codec is retrieved and input into the next step.<br>\n",
    "            \n",
    "2)Re-encode the main video to audio = PCM: <br>\n",
    "<i>ffmpeg -y -i media_files/marines_5min.mov -r 25.0 -c:v libx264 -c:a pcm_s16le -ar 44100 -ac 2 -preset fast -crf 18 marines_5min_tmp.mov</i><br><br>\n",
    "3)Rescaling video to match the main video's dimension:<br>\n",
    "<i>ffmpeg -y -i marines_5min_tmp.mov -vf scale=556:412,pad=556:412:0:0:black -c:v libx264 -preset fast -crf 18 -c:a copy marines_5min_reencoded.mov</i><br><br>\n",
    "4)Pad/truncate audio to match video duration:<br>\n",
    "<i>ffmpeg -y -i marines_5min_reencoded.mov -c:v copy -af apad,atrim=0:300.000000 marines_5min_reencoded_padded.mov</i><br>\n",
    "\n",
    "So the final product we want is the last one - <i>marines_5min_reencoded_padded.mov</i>. The same procedure applies to other videos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120f0365-bca9-4e66-9ec6-ef15fbd03640",
   "metadata": {},
   "outputs": [],
   "source": [
    "from video_commands import * \n",
    "main_video = \"media_files/marines_5min.mov\"\n",
    "# The main video serves as the \"standard\" codec for others to follow\n",
    "list_to_reencode = [main_video,\"video1.mov\",\"video2.mov\",\"video3.mov\",\"video4.mov\",\n",
    "            \"black1.mov\",\"black2.mov\",\"black3.mov\"]\n",
    "reencoded_file_names, reencoded_file_dict =reencode_to_match(main_video, list_to_reencode,crf=\"50\", preset=\"ultrafast\")\n",
    "\"\"\"\n",
    "reencoded_file_names are the new file names and reencoded_file_dict is a dictionary with old video names as the key and\n",
    "reencoded videos as the value\n",
    "\"\"\"\n",
    "print_media_info(reencoded_file_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b817112-349e-4ca0-b7e6-cdfe64b58953",
   "metadata": {},
   "source": [
    "Now we have the reencoded video name, and we can check the codec again. The reencoded video has a default new name. If the original name is <i>xxx.mov </i>, then the new name:  <i>xxx_reencoded_padded.mov </i>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010dd1f1-2dfa-4143-a511-5f08e84a1e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_videos = [\"video1_reencoded_padded.mov\",\"video2_reencoded_padded.mov\",\"video3_reencoded_padded.mov\",\n",
    "\"video4_reencoded_padded.mov\",\"black1_reencoded_padded.mov\",\"black2_reencoded_padded.mov\",\n",
    "                 \"black3_reencoded_padded.mov\"]\n",
    "print_media_info(list_of_videos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebcf3d5-722b-4bcf-9544-b52ad2ec1544",
   "metadata": {},
   "source": [
    "You see now the audio and video duration, and the codec are all the same. We can combine them safely now. The code creates a temporary folder and put all the intermediate files there. It first reencode all the videos to convert them to the same codec, then combine them. <b>Remember the above function <i>reencode_to_match()</i> is unnecessary.</b><br>\n",
    "Now let's combine the videos:<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a621bae3-66a3-4117-ad11-57bf926e87ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input the video list in order of concatenation\n",
    "video_list = [\"video1.mov\",\"black1.mov\",\"video2.mov\",\"black2.mov\",\"video3.mov\",\"black3.mov\",\"video4.mov\"]\n",
    "#primary index is the video which serves as a \"model\" for reencoding. All other videos will have the same codec as this one. \n",
    "#Note the first video has a primary_index \"1\", not \"0\"\n",
    "combine_video(video_list, primary_index=1, output_file=\"marines_5min_new.mov\", crf=18, preset=\"fast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7cf56c-6284-488a-a3d7-9708f1c8bf18",
   "metadata": {},
   "source": [
    "Now you run the code below and you can see the black stills at 1:30, 2:35 and 4:10, each lasts for 5s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f56843-ca48-455a-accf-c66bb62191e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Jou_m0InGRQ\" frameborder=\"0\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d889be63-ed74-473a-8035-e823e8161e1e",
   "metadata": {},
   "source": [
    "<h3 align =center>Separating the audio channels of a video</h3>\n",
    "Sometimes the video have different audio channels, i.e. background music and narration. This would bring difficulties when we convert the audio to subtitles. We need to separate the channels first. <i>demucs</i> is a very powerful tool to use. You end up having a file called <i>vocals.wav</i>, this is the file for the subtitle. This process may take around half an hour. I have difficulty implementing <i>demucs</i> using python. I am giving up. Just run the following in the command line.<b>Remember to switch to the python environment where <i>whisper</i> is in to run this.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e151aa8b-0973-4628-a900-9bb5f995e664",
   "metadata": {},
   "source": [
    "copy and paste and in the terminal. Don't run it here! The output is in default folders <b><i>separated/htdemucs/marines_5min_new</i></b>\n",
    "\n",
    "<i><b>demucs -o media_files media_files/marines_5min_new.mov</i></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a760f58-5917-42af-8596-0949cd1d83f7",
   "metadata": {},
   "source": [
    "Now in <i>separated/htdemucs/marines_5min_new</i>, we find <i>vocals.wav</i>. We use this file to extract the subtitles. This process takes 10-20 mins.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb082c6-5c4a-4fe5-a7e6-342583c9fafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input can be a video or audio. If video, make sure the audio channel is \"clean\"\n",
    "video = \"separated/htdemucs/marines_5min_new/vocals.wav\"\n",
    "outputsrt = \"subtitle.srt\"\n",
    "voice_to_srt(video, outputsrt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6e561f-baf3-4c30-b5fe-1e348f159d75",
   "metadata": {},
   "source": [
    "If there are any mistakes in the subtitle file <i>subtitle.srt</i>, just correct it and we will proceed to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e29fb99-4b0d-492d-817e-7be90b44a9de",
   "metadata": {},
   "source": [
    "<h3 align=center>Translating the subtitle to different languages</h3>\n",
    "If you use deepl, you need an api key. You can get a free one. I provide an empty file <i>api_deepl.txt</i> for you to input the key. If you don't want to use it, then just use <i>google translate</i>.<br>\n",
    "For google translate, here is the code for some common languages:<br><br>\n",
    "\n",
    "<i>english = en<br>\n",
    "simplified chinese = \"zh-CN\" for google, \"zh\" for deepl<br>\n",
    "traditional chinese = \"zh-TW\" for google, \"zh\" for deepl<br>\n",
    "japanese = ja<br>\n",
    "korea = ko<br>\n",
    "german = de<br>\n",
    "french = fr<br></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b563fe99-a84a-474a-a9d8-c3bb453cc607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1\\n00:00:00.000 --> 00:00:03.399\\n機関銃の代わりに私たちの直腸のピビオンまで。\\n\\n2\\n00:00:06.560 --> 00:00:09.500\\n彼らは私たちの何人かを手に入れました、私たちが彼らを手に入れました。\\n\\n3\\n00:00:14.280 --> 00:00:16.120\\n暴行部隊の指揮官\\n\\n4\\n00:00:16.120 --> 00:00:17.580\\nこのタスクを確認しました。\\n\\n5\\n00:00:18.760 --> 00:00:21.359\\n中程度のタンクの1つは稼働中です。\\n\\n6\\n00:00:21.359 --> 00:00:32.859\\n2日目の終わりには、Dプラス1つですが、少し簡単に呼吸します。\\n\\n7\\n00:00:32.859 --> 00:00:36.359\\nモルタル分隊は、敵の抵抗点を攻撃し続けます。\\n\\n8\\n00:00:51.359 --> 00:00:59.359\\nこの時までに、私たちは日本人がそれを知っていなければならないことを知っています。\\n\\n9\\n00:00:59.359 --> 00:01:01.359\\n彼らはまだ強い抵抗です。\\n\\n10\\n00:01:01.359 --> 00:01:06.359\\nニップの自殺、狙撃兵は木の上に縛り付けて、私たちにポットショットを撮ります。\\n\\n11\\n00:01:06.359 --> 00:01:11.359\\n彼らは倒れず、ただ死んでそこにぶら下がっています。\\n\\n12\\n00:01:21.359 --> 00:01:26.359\\n日本軍が稼働しています。\\n\\n13\\n00:01:26.359 --> 00:01:31.359\\n彼らはまだ強い抵抗です。\\n\\n14\\n00:01:31.359 --> 00:01:36.359\\n彼らはまだ強い抵抗です。\\n\\n15\\n00:01:36.359 --> 00:01:41.359\\n彼らはまだ強い抵抗です。\\n\\n16\\n00:01:41.359 --> 00:01:45.359\\n彼らはまだ強い抵抗です。\\n\\n17\\n00:01:45.359 --> 00:01:50.359\\n日本軍が稼働しています。\\n\\n18\\n00:01:50.359 --> 00:01:55.359\\n彼らはまだ強い抵抗です。\\n\\n19\\n00:01:55.359 --> 00:02:00.359\\n日本軍が稼働しています。\\n\\n20\\n00:02:00.359 --> 00:02:05.359\\n彼らはまだ強い抵抗です。\\n\\n21\\n00:02:05.359 --> 00:02:10.360\\n日本軍が稼働しています。\\n\\n22\\n00:02:11.360 --> 00:02:15.360\\n軽いタンクがエアストリップを移動します。\\n\\n23\\n00:02:20.360 --> 00:02:24.360\\n私たちの男の子の一人は、飛行場への攻撃中に負傷します。\\n\\n24\\n00:02:24.360 --> 00:02:31.360\\n別の海兵隊員が彼の後に出て、重い機関銃の火の下で安い。\\n\\n25\\n00:02:41.360 --> 00:02:43.360\\nビーチに戻ると、絶え間ない活動があります。\\n\\n26\\n00:02:43.360 --> 00:02:46.360\\n両生類、つま先の新鮮なサプライヤー、誰？\\n\\n27\\n00:02:46.360 --> 00:02:52.360\\nアンモニア銃。\\n\\n28\\n00:02:52.360 --> 00:02:56.360\\n戦いが島を横切って移動するにつれて、アウスの牧師は死んでいる傾向があります、\\n\\n29\\n00:02:56.360 --> 00:03:00.360\\nより低い識別を削除し、各海兵隊の複製を離れる\\n\\n30\\n00:03:00.360 --> 00:03:04.360\\nしたがって、後で間違いはありません。\\n\\n31\\n00:03:05.360 --> 00:03:10.360\\n将軍ホロンスミスとジュリアン・スミスが部隊と師団を指揮しています。\\n\\n32\\n00:03:10.360 --> 00:03:15.360\\nハリー・ヒル提督がタスクフォースを指揮しています。\\n\\n33\\n00:03:15.360 --> 00:03:20.360\\n時々、私たちは実際に彼らの穴からチャップを掘り出さなければなりません。\\n\\n34\\n00:03:20.360 --> 00:03:23.360\\n島にはさまざまなピルボックスが寄生しています。\\n\\n35\\n00:03:23.360 --> 00:03:26.360\\nそれらの多くはまだチャップスでrawいをしています。\\n\\n36\\n00:03:26.360 --> 00:03:31.360\\nこれらのバンカーはそのように構築されていたため、重い砲撃と解体の料金はそれらを砕くことができませんでした。\\n\\n37\\n00:03:31.360 --> 00:03:34.360\\nそれらの多くは深さ20フィート以上でした。\\n\\n38\\n00:03:40.360 --> 00:03:43.360\\n私たちの最初の囚人。\\n\\n39\\n00:03:52.360 --> 00:03:56.360\\n負傷者は畑で応急処置を与えられ、担架でボートに運ばれます。\\n\\n40\\n00:03:57.360 --> 00:04:02.360\\n彼らと一緒に、海軍病院、普通、海軍の医師や外科医が常にあります。\\n\\n41\\n00:04:04.360 --> 00:04:09.360\\n輸送では、鋼鉄のリッターがはしけから持ち上げられ、穴に下げられます。\\n\\n42\\n00:04:09.360 --> 00:04:14.360\\n彼らは...\\n\\n43\\n00:04:14.360 --> 00:04:17.360\\n...そして船の病院に。\\n\\n44\\n00:04:17.360 --> 00:04:20.360\\n2番目のものがどのように失われるか。\\n\\n45\\n00:04:21.360 --> 00:04:27.360\\nこれらは海洋死者です。\\n\\n46\\n00:04:30.360 --> 00:04:34.360\\nこれは、私たちが望んでいない戦争のためにあなたに支払わなければならない価格です。\\n\\n47\\n00:04:34.360 --> 00:04:39.360\\nそこにある前に、他の戦場よりも死んでしまうでしょう。\\n\\n48\\n00:04:50.360 --> 00:04:56.360\\n行動中に殺された海兵隊の船に乗った樽。\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from video_commands import *\n",
    "subtitle_file = \"subtitle.srt\"\n",
    "outputfile = \"subtitle_google_ja.srt\"\n",
    "target_lang = \"ja\"\n",
    "source_lang = \"en\" #not inputting this would set the value to auto-detect\n",
    "translate_srt_google(subtitle_file,outputfile, target_lang, source_lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4891fc3e-5912-40e1-a476-062ac19592b3",
   "metadata": {},
   "source": [
    "If you have deepl api, then here it is. When you open the output file <i>subtitle_jp.srt</i>. Deepl always get the last sentence untranslated. You have to do this manually. If you translate to Chinese, the output can be traditional or simplified chinese, or a mixture of both. I convert the output to simplfied Chinese in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84219e5-beed-48c3-9658-7cfefaddb1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtitle_file = \"subtitle.srt\"\n",
    "outputfile = \"subtitle_deepl_zh.srt\"\n",
    "target_lang = \"zh\" \n",
    "source_lang = \"en\" #not inputting this would set the value to auto-detect\n",
    "deepl_translate_srt(subtitle_file, outputfile,target_lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8a21ea-5519-45ae-ae5c-c48f42ec0d91",
   "metadata": {},
   "source": [
    "We will just leave the subtitle here right at the moment. When the final video is done. We will convert it to ass format and burn in to the video."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56829ff-ef5a-4b1d-a951-25297cb905ec",
   "metadata": {},
   "source": [
    "<h3 align = center >Overlaying videos, images and music</h3>\n",
    "\n",
    "<b>In the last step of this section, we will overlay all the videos, images and music to the main video in one step. But now I am breaking down each step for tutorial purpose. You can look for \"overlaying everything\" directly and skip the details here.</b><br><br>\n",
    "Now we can proceed to overlaying other videos, images and music on the main video. We can even zoom in an image. Let's proceed with overlaying videos on the main video first.<br>\n",
    "<h5>1.Overlaying a video</h5>\n",
    "For the overlay video, we need to remove the audio first. The first step is to check whether there is an audio stream: <br> \n",
    "<i>ffprobe -i media_files/Aumun_Background.mov -show_streams -select_streams a -loglevel error</i><br> <br>\n",
    "\n",
    "Next, the audio is removed from the video, or you can choose a <i>volume factor</i> to lower the audio volume:<br> \n",
    "<i>ffmpeg -y -i media_files/Aumun_Background.mov -filter:a volume=0 -c:v copy ./Aumun_Background_muted.mov</i><br>\n",
    "\n",
    "The default name for the muted video is <i>xxx_muted.mov</i>, or <i>xxx_0.2.mov</i>, if you choose the lower the audio to 20% of the original. This product would be used in the next step.<br>\n",
    "\n",
    "Finally, the audio is saved as a separate wav file <i>Aumun_Background.wav</i>:<br>\n",
    "<i>ffmpeg -i media_files/Aumun_Background.mov -vn -acodec pcm_s16le -ar 44100 -ac 2 ./Aumun_Background.wav</i><br><br>\n",
    "If you don't want it, you can discard it.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e5f616-71ae-4d77-998a-f0c14e009018",
   "metadata": {},
   "outputs": [],
   "source": [
    "from video_commands import *\n",
    "video = \"media_files/Aumun_Background.mov\"\n",
    "outfolder = \".\"\n",
    "volume_factor = 0\n",
    "separate_audio_video(video,outfolder,volume_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22d76a2-e453-4442-bce4-e32ee2085875",
   "metadata": {},
   "source": [
    "Next, do the re-encoding to match the audio and video codec to the main video. You can check the codec of the videos after reencoding\n",
    ":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b8d0db-452a-41c1-9a32-2293a489e2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_video = \"marines_5min_new.mov\"\n",
    "list_to_reencode = [main_video,\"Aumun_Background_muted.mov\"]\n",
    "reencoded_file_names, reencoded_file_dict =reencode_to_match(main_video, list_to_reencode,crf=\"18\", preset=\"fast\")\n",
    "print(reencoded_file_names)\n",
    "print_media_info(reencoded_file_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3624da42-d5f5-4d76-8645-46d5883c71e4",
   "metadata": {},
   "source": [
    "Finally, we can do the overlay. Note that the function <i>overlay_video_img_music</i> actually incorporates <i>reencode_to_match()</i>. You just have to input the raw media files.<br>\n",
    "What you need is a parameter list as a list of list:<br>\n",
    "\n",
    "<i>para_list = [[\"media_files/Aumun_Background.mov\",\"0:30\",\"0:45\",\"0:05\",3]]</i><br><br>\n",
    "We want to overlay <i>media_files/Aumun_Background.mov\"(1st parameter)</i> from <i>time=30 seconds(2nd parameter)</i> to <i>time=45 seconds(3rd parameter)</i> of the main video. <i>\"media_files/Aumun_Background.mov</i> last for 29 seconds and we want to extract the part of this video starting from <i>5s(4th parameter)</i>. That means we overlay (5-20)s of <i>media_files/Aumun_Background.mov</i> to (30-45)s of the main video. The fade out time is <i>3s(final parameter)</i>.<br>\n",
    "\n",
    "For the time parameters(2nd,3rd and 4th parameters), they can be input as an integer, or as \"mm:ss\" or \"hh:mm:ss\". Fade-in and fade-out should be in seconds(an integer)<br><br>\n",
    "\n",
    "Now, let's do it:<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ac9259-de78-4824-af32-03d9d0b60cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_video = \"marines_5min_new.mov\"\n",
    "end_time = get_video_length(main_video)\n",
    "para_list = [[\"media_files/Aumun_Background.mov\",\"0:30\",\"0:45\",\"0:05\",3]]\n",
    "outputfile = \"marines_5min_video_overlay.mov\"\n",
    "overlay_video_img_music(main_video, para_list, outputfile, crf=18, preset=\"fast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784204b3-d0a1-423b-a6d8-2ca631ef6ba3",
   "metadata": {},
   "source": [
    "Now you can run the code below to see the newly created file <i>marines_5min_video_overlay.mov</i>. Go to time = 0:30 and you can see the overlay until 0:45, with fade-out starting 5 seconds before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36a31d6-1bc1-4bec-b096-37a71b374fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/PtlQhHtLjKs\" frameborder=\"0\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30793398-e131-4d34-9e22-576161fa6e87",
   "metadata": {},
   "source": [
    "<h5>Overlaying images</h5>\n",
    "Next, we can proceed to overlaying images. If we want to have a zoom-in effect, we need to turn the image into a video first. But the first step is to decide the focus of the zoom in. This step is actally more complicated with <i>ffmpeg </i> than interface software. For the following image, suppose we want to zoom in to the boat. We need to rescale the image(<i>media_files/boat.jpg</i>) to match the main video and then add a grid to get the coordinate.\n",
    "<p align=\"center\">\n",
    "    <img src=\"https://helen-poon.github.io/ffmpeg_video/media_files/boat.jpg\" \n",
    "         alt=\"Black screen separator\" \n",
    "         style=\"max-width: 50%; height: auto;\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6153fb5-5bce-493b-a670-fe4cbd93cbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_video = \"marines_5min_new.mov\" #we need to rescale the input image to match the size of the main video\n",
    "video_width,video_height = get_media_dimensions(main_video) \n",
    "image_name = \"media_files/boat.jpg\" #the input image\n",
    "#the rescaled image which matches the dimensions of the main video. This file is used as the overlay\n",
    "output_filename = \"boat_rescaled.jpg\" \n",
    "make_rescaled_image(video_width, video_height, image_name, output_filename) #produce the rescaled image\n",
    "input_file = output_filename\n",
    "output_file = \"boat_rescaled_grid.jpg\"\n",
    "#add a grid to the rescaled image to retrieve pixel positions, setting an interval = 50 means the distance between the grid is 50 pixels\n",
    "add_numbered_grid(input_file, output_file,video_width,video_height,interval=50,line_color=\"red\",number_color=\"black\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16328503-9285-466f-b93e-c14a23908a6b",
   "metadata": {},
   "source": [
    "Here is the newly created <i>boat_rescaled_grid.jpg</i>. <b>Top left corner has x = 0, y = 0 </b>. Since the size of the grid is 50 pixels. We can see the boat has a coordinate x = 275, y=275.\n",
    "<p align=\"center\">\n",
    "    <img src=\"https://helen-poon.github.io/ffmpeg_video/boat_rescaled_grid.jpg\" \n",
    "         alt=\"Black screen separator\" \n",
    "         style=\"max-width: 50%; height: auto;\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665c2aca-c947-44c3-b740-fca2bb7c85d0",
   "metadata": {},
   "source": [
    "Now we can produce the video with the zoom in. Below we want to make a video out of <i>boat_rescaled.jpg</i>. The video has a duration of 5 seconds. Starting from 2 second of the overlay, zoom in starts to the position x = 275, y = 275. The magnification is 2. The output file name is <i>boat_video.mov</i>.\n",
    "We have to input the above as a list of list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdc58d6-a899-4836-b49e-ebd17dd97006",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pos,y_pos = 275,275\n",
    "duration = 5\n",
    "zoom_start = 2\n",
    "zoom_max = 2\n",
    "out_file = \"boat_video.mov\"\n",
    "image_list = [[\"boat_rescaled.jpg\", x_pos, y_pos, duration, zoom_start, zoom_max, out_file]]\n",
    "create_zoom(image_list, main_video, crf=18, preset=\"fast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5318a26-6924-4792-87a3-e5ee1553f94e",
   "metadata": {},
   "source": [
    "Now run the following and you can see the video of 5s with a zoom-in to the boat starting at time = 2s. With this video, you can overlay it to the main video like we just did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c140d044-fede-4e6e-9ea1-e9af59419e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/sDrC1RSrT2o\" frameborder=\"0\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652495ee-15e2-40fd-86a2-4cde14b1682f",
   "metadata": {},
   "source": [
    "Next, we just simply want to overlay an image. We call the function <i>overlay_video_img_music()</i> again. Remember we have to enter a parameter list as a list of list, this time in the format for an image. We want to overlay <i>boat_rescaled.jpg(1st parameter)</i> from <i>1:50-1:55(2nd and 3rd parameter)</i> on the main video, with a <i>fade-out = 2s (last parameter)</i>.<br>\n",
    "<i>para_list = [[\"boat_rescaled.jpg\",\"1:50\",\"1:55\",\"2\"]]</i> <br>\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab9f9fd-9aef-4575-ab08-6876aa9dbaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "para_list = [[\"boat_rescaled.jpg\",\"1:50\",\"1:55\",\"2\"]]\n",
    "output_file = \"marines_5min_img_overlay2.mov\"\n",
    "overlay_video_img_music(main_video, para_list, output_file, crf=23, preset=\"veryfast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65af65b0-31d9-4258-99bd-9a8a09662bd1",
   "metadata": {},
   "source": [
    "Now run the following and you see the overlay image from 1:50 - 1:55, with fadeout starting at 1:53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9299f232-8a8a-447b-89b2-4e8f61c7abd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/EZ3qWLFfw2M\" frameborder=\"0\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cc29bd-f08c-46cb-a805-ddcf43064e42",
   "metadata": {},
   "source": [
    "<h5>Overlaying music</h5>\n",
    "Finally, we overlay music. Here is the parameter list for music:<br><br>\n",
    "\n",
    "<i>end_time = get_video_length(main_video)</i><br>\n",
    "<i>para_list = [[\"media_files/Mozart.wav\",\"0:30\",f\"{end_time}\",3,4,2]]</i><br><br>\n",
    "We want to overlay <i>\"media_files/Mozart.wav\"(1st parameter)</i> from <i>time=30 seconds(2nd parameter)</i> to <i>the end(3rd parameter)</i> of the main video (the end time is retrieved via <i>get_video_length()</i>), with a <i>fade-in</i> and <i>fade-out</i> time = <i>3(4th parameter)</i> and <i>4 seconds(5th parameter)</i> respectively. And we want to make the music volume <i>2 times </i> the original.<br>\n",
    "\n",
    "If the music has a shorter duration than the overlay time, it would repeat itself. For the overlay time parameters(2nd and 3rd parameters), they can be input as an integer, or as \"mm:ss\" or \"hh:mm:ss\". Fade-in and fade-out should be in seconds(an integer)<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5b7a82-e2e4-4575-a2be-d50caa2603ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_video = \"marines_5min_new.mov\"\n",
    "end_time = get_video_length(main_video)\n",
    "para_list = [[\"media_files/Mozart.wav\",\"0:30\",f\"{end_time}\",3,4,2]]\n",
    "outputfile = \"marines_5min_music.mov\"\n",
    "overlay_video_img_music(main_video, para_list, outputfile, crf=23, preset=\"fast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ffe39f-7d83-4093-bda2-d04ad7dd5a2b",
   "metadata": {},
   "source": [
    "Now run the following and you can hear the music starting from time = 30s to the end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70bd707-6a60-4d51-bb35-e76592b7df0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/ane1G4ckd_Q\" frameborder=\"0\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17ff20f-206d-4fd5-9939-89595ad59593",
   "metadata": {},
   "source": [
    "<h3 align = center>Overlaying everything</h3>\n",
    "Now we come to the most critical part - overlaying everthing. We have a main video <i>marines_5min_new.mov</i>\n",
    "Here are what we want to overlay:<br><br>\n",
    "1. overlay the video <i>media_files/Aumun_Background.mov</i> from 0:20-0:30 of the main video. <i>media_files/Aumun_Background.mov</i> should be extracted from time=5s. No fade-out time.<br>\n",
    "2. overlay the image-turn-video <i>boat_video.mov </i> from 3:30-3:35 of the main video. We already make <i>boat_video.mov </i> 5s.<br>\n",
    "3. overlay the video <i>media_files/Mountain_Forest.mov</i> from 4:00-4:15 of the main video. <i>media_files/Mountain_Forest.mov</i> should be extracted from the start. Fade-out time = 3s<br>\n",
    "4. Overlay the image <i>media_files/bridge.jpg</i> from 0:10-0:15 of the main video. Fade-out = 1s.<br>\n",
    "5. Overlay the image <i>media_files/kochi.jpg</i> from 2:00-2:15 of the main video. Fade-out = 5s.<br>\n",
    "6. Overlay the image <i>media_files/cat.jpg</i> from 3:00-3:03 of the main video. No fade-out.<br>\n",
    "7. Overlay the music <i>media_files/Mozart.wav</i> from 0:10-3:00 of the main video. Fade-in and fade-out = 5s. Music volume 3 times the original.<br>\n",
    "8. Overlay the music <i>media_files/Rachmaninoff.wav</i> from 3:10-the end of the main video. Neither fade-in nor fade-out.Original volume.<br><br>\n",
    "\n",
    "When we define the parameter list, we first have to categorize them, then put them in order of appearance. Like the above, I put video first, then image and finally music. They are already in order of appearance. The parameter list looks like this:<br><br>\n",
    "<i>\n",
    "end_time = get_video_length(main_video)<br>\n",
    "para_list = [[\"media_files/Aumun_Background.mov\",\"0:20\",\"0:30\",\"0:05\",0],<br>\n",
    "             [\"boat_video.mov\",\"3:30\",\"3:35\",\"0:00\",0],<br>\n",
    "             [\"media_files/Mountain_Forest.mov\",\"4:00\",\"4:15\",\"0:00\",3],<br>\n",
    "             [\"media_files/kochi.jpg\",\"1:50\",\"1:55\",\"2\"],<br>\n",
    "             [\"media_files/bridge.jpg\",\"2:00\",\"2:15\",\"5\"],<br>\n",
    "             [\"media_files/cat.jpg\",\"3:00\",\"3:03\",\"0\"],<br>\n",
    "             [\"media_files/Mozart.wav\",\"0:10\",\"3:00\",5,5,3],<br>\n",
    "             [\"media_files/Rachmaninoff.wav\",\"3:10\",f\"{end_time}\",0,0,1]]<br>\n",
    "\n",
    "\n",
    "</i>\n",
    "\n",
    "Let's create the final product.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787468f7-2075-4825-8bec-aa952e60f8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from video_commands import *\n",
    "main_video = \"marines_5min_new.mov\"\n",
    "end_time = get_video_length(main_video)\n",
    "para_list = [[\"media_files/Aumun_Background.mov\",\"0:20\",\"0:30\",\"0:05\",0],\n",
    "[\"boat_video.mov\",\"3:30\",\"3:35\",\"0:00\",0],\n",
    "[\"media_files/Mountain_Forest.mov\",\"4:00\",\"4:15\",\"0:00\",3],\n",
    "[\"media_files/kochi.jpg\",\"1:50\",\"1:55\",\"2\"],\n",
    "[\"media_files/bridge.jpg\",\"2:00\",\"2:15\",\"5\"],\n",
    "[\"media_files/cat.jpg\",\"3:00\",\"3:03\",\"0\"],\n",
    "[\"media_files/Mozart.wav\",\"0:10\",\"3:00\",5,5,3],\n",
    "[\"media_files/Rachmaninoff.wav\",\"3:10\",f\"{end_time}\",0,0,1]]\n",
    "output_file = \"marines_5min_all_overlay.mov\"\n",
    "overlay_video_img_music(main_video, para_list, output_file, crf=23, preset=\"veryfast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1d7046-1f9a-4100-bd3e-4e283d825a50",
   "metadata": {},
   "source": [
    "Now run the following and you can see:\n",
    "1) 0:10 - 3:00 music\n",
    "2) 0:20 - 0:30 an overlay video with no fadeout\n",
    "3) 1:50 - 1:55 an overlay image with fadeout = 2s\n",
    "4) 2:00 - 2:15 an overlay image with fadeout = 5s\n",
    "5) 3:00 - 3:03 an overlay image with no fadeout\n",
    "6) 3:10 - the end music\n",
    "7) 3:30 - 3:35 an overlay video which zooms in to the boat\n",
    "8) 4:00 - 4:15 an overlay video with fadeout = 3s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cac55b-9105-4b60-9d88-455d05e3dec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/GYVAkAYAVwo\" frameborder=\"0\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976161ec-bc06-4a07-87a3-da87b9175e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c166cd9-4e21-4f00-a013-d664b305eedb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
